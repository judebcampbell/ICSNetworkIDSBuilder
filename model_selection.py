'''
model_selection module

Contains all functions related to training and tuning models
'''

import json

'''
Function returns a set of pipelines for training; range of models used.
Can expand selection;
	for evaluation preprocessing options or additional models
	if expanded need to add new .json file to model_parameters
		containing search grid for new pipe
'''
def generatePipeline():
	pipelines = []
	pipelines.append(('RandomForest', (Pipeline([('RandomForest', RandomForestClassifier())]))))
	pipelines.append(('SGDC', (Pipeline([('SGDC', SGDClassifier())]))))
	pipelines.append(('Gaussian', (Pipeline([('GaussianNB', GaussianNB())]))))
	pipelines.append(('DecisionTree', (Pipeline([('DecisionTree', DecisionTreeClassifier())]))))
	pipelines.append(('KNN', (Pipeline([('KNN', KNeighborsClassifier())]))))
	pipelines.append(('SVC', (Pipeline([('SVC', SVC())]))))
	return(pipelines)


'''
Function trains models generated by the function generatePipelines
inputs:
	X - dataframe of training values
	Y - Target classes for each row of the dataframe
	k-  number of cross validation splits to use (default 5)
Returns
	model_names - list of model names
	results - list with dictionary containing, times and scores
	pipelines - the pipelines trained on
'''
def trainModels(X,Y,k=5):
	pipelines = generatePipeline()
	model_names = []
	results = []
	for pipe, model in pipelines:
		kfold = KFold(n_splits=k)
		# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter
		crossv_results =  cross_validate(model, X, Y, cv=kfold, scoring=['balanced_accuracy',
						 'f1', 'precision', 'recall', 'roc_auc'])

		results.append(crossv_results)
		model_names.append(pipe)
	
	
	return(model_names, results, pipelines)

'''
Function tunes models using search grids defined in /model_parameters folder
inputs: 
	model_names - a list of the models in pipelines to be optimised
	pipelines - the pipeline list of models generated for training
	X - dataframe of training values
	Y - target classes for X
	k - number of cross folds to validate on (default 10)
outputs:
	model_names - list of models optimised
	results -  list with dictionary containing, times and scores
	models -  list containing the optimised models
'''
def hyperparameterTuning(model_names, pipelines, X, Y, k=10):

	results = []
	tuned_models = []

	for pipe, model in pipelines:
		if pipe in model_names:
			print('\n\nTuning ' + str(pipe))
			filecomposed = 'model_parameters/' + str(search)  + '.json'
			if os.path.isfile(filecomposed):
				f = open(filecomposed)
				params = json.load(f)

			clf = RandomizedSearchCV(estimator=model, param_distributions=params, cv=k)
			search = clf.fit(X, Y)

			crossv_results =  cross_validate(search.best_estimator_, X, Y, cv=kfold, 
							scoring=['balanced_accuracy', 'f1', 'precision', 'recall', 'roc_auc']
						)

			results.append(crossv_results)
			tuned_models.append(search.best_estimator_)

	return(model_names, results, tuned_models)

'''
Function evaluates a given set of cross validated set of results to
pick the best n models
inputs:
	results - list with dictionary containing different metrics
	modelnames - list of model names in same order as results
	n - number of models to be selected
	models - list of models / only passed if you want a model returned (default = None)
outputs:
	best_model_names: list of the best n models
	models: best n models found
'''
def evaluateModels(results, modelnames, n=3, models = None):
	means = []
	stds = []
	best_models_names= []
	best_model = []

	for r in results:
		means.append(r['test_balanced_accuracy'].mean())
		stds.append(r['test_balanced_accuracy'].std())
	
	#sort the means and get their index for finding model/model name
	locations = sorted(range(len(means)), key=lambda i: means[i])[-n:]
	for l in locations:
		#print("\n" +  str(modelnames[l]) + " Average F1: " + str(means[l]) + " Standard Deviation: " + str(stds[l]))
		best_models_names.append(modelnames[l])

		if models != None:
			best_model = models[l]

	if models != None:
		return(best_models_names, best_model)
	else:
		return(best_models_names)